{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Prerequisite","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\nimport numpy as np\nimport time\nimport glob\nimport shutil\nimport cv2\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport torchvision\nimport copy\nimport requests\nimport random\n\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import models\nfrom torchvision.datasets import CIFAR10, CIFAR100, MNIST, FashionMNIST, SVHN, ImageFolder\nfrom torchvision import transforms\nfrom torchvision.models import resnet\nfrom torch.utils.data.dataset import Dataset \nfrom torch.utils.data import DataLoader\nfrom PIL import Image\nfrom glob import glob\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score\nfrom torchvision.utils import save_image\nfrom torchvision.utils import make_grid","metadata":{"id":"lNnqCAYxWhCJ","execution":{"iopub.status.busy":"2023-05-24T19:02:26.289260Z","iopub.execute_input":"2023-05-24T19:02:26.289719Z","iopub.status.idle":"2023-05-24T19:02:31.171515Z","shell.execute_reply.started":"2023-05-24T19:02:26.289683Z","shell.execute_reply":"2023-05-24T19:02:31.170528Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"! pip install torchattacks\nfrom torchattacks import FGSM, PGD","metadata":{"id":"2viX32NvXARp","outputId":"1647bbd3-ee33-4157-9a19-6fbb6b341399","execution":{"iopub.status.busy":"2023-05-24T19:02:31.173179Z","iopub.execute_input":"2023-05-24T19:02:31.173749Z","iopub.status.idle":"2023-05-24T19:02:44.143525Z","shell.execute_reply.started":"2023-05-24T19:02:31.173715Z","shell.execute_reply":"2023-05-24T19:02:44.142416Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting torchattacks\n  Downloading torchattacks-3.4.0-py3-none-any.whl (154 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (2.0.0)\nRequirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (0.15.1)\nRequirement already satisfied: scipy>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.10.1)\nRequirement already satisfied: tqdm>=4.56.1 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (4.64.1)\nCollecting requests~=2.25.1 (from torchattacks)\n  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.10/site-packages (from torchattacks) (1.23.5)\nCollecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.25.1->torchattacks) (2023.5.7)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.1->torchattacks) (3.1.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.8.2->torchattacks) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.1->torchattacks) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.1->torchattacks) (1.3.0)\nInstalling collected packages: idna, chardet, requests, torchattacks\n  Attempting uninstall: idna\n    Found existing installation: idna 3.4\n    Uninstalling idna-3.4:\n      Successfully uninstalled idna-3.4\n  Attempting uninstall: requests\n    Found existing installation: requests 2.28.2\n    Uninstalling requests-2.28.2:\n      Successfully uninstalled requests-2.28.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 10.0.1 which is incompatible.\nbeatrix-jupyterlab 2023.58.190319 requires jupyter-server~=1.16, but you have jupyter-server 2.5.0 which is incompatible.\ndocker 6.1.1 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\ngoogle-cloud-artifact-registry 1.8.1 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.33.2 which is incompatible.\ngoogle-cloud-datastore 2.15.2 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.33.2 which is incompatible.\ngoogle-cloud-dlp 3.12.1 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.33.2 which is incompatible.\ngoogle-cloud-pubsub 2.16.1 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.33.2 which is incompatible.\ngoogle-cloud-pubsub 2.16.1 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\ngoogle-cloud-resource-manager 1.10.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.33.2 which is incompatible.\ngoogle-cloud-spanner 3.33.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 1.33.2 which is incompatible.\njupyterlab-lsp 4.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-server 2.22.1 requires requests>=2.28, but you have requests 2.25.1 which is incompatible.\nkfp 1.8.21 requires google-api-python-client<2,>=1.7.8, but you have google-api-python-client 2.86.0 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.1.2 requires scipy<1.10,>=1.4.1, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed chardet-4.0.0 idna-2.10 requests-2.25.1 torchattacks-3.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gdown\nimport gdown\n!pip install --upgrade --no-cache-dir gdown\n!gdown 1xKuFbhpdLMBQ3pT2TmC9Pj9tKKIZgHaX","metadata":{"id":"4DA9NjBWWPQ7","outputId":"7cfacf84-f8af-4e0e-9d66-f726d6a6ea58","execution":{"iopub.status.busy":"2023-05-24T19:02:44.145630Z","iopub.execute_input":"2023-05-24T19:02:44.145990Z","iopub.status.idle":"2023-05-24T19:03:16.097197Z","shell.execute_reply.started":"2023-05-24T19:02:44.145956Z","shell.execute_reply":"2023-05-24T19:03:16.096001Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.25.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (4.7.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.25.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (4.0.0)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mDownloading...\nFrom: https://drive.google.com/uc?id=1xKuFbhpdLMBQ3pT2TmC9Pj9tKKIZgHaX\nTo: /kaggle/working/mnist_GLIDE_NormalClass0_6450.npy\n100%|██████████████████████████████████████| 78.9M/78.9M [00:01<00:00, 57.8MB/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"exposure_addr = './mnist_GLIDE_NormalClass0_6450.npy'\n\nimage_size = 32\n\ntrain_attack_epses = [8/255]","metadata":{"id":"zVQBRgI1Y0NG","execution":{"iopub.status.busy":"2023-05-24T19:11:06.039121Z","iopub.execute_input":"2023-05-24T19:11:06.040298Z","iopub.status.idle":"2023-05-24T19:11:06.046356Z","shell.execute_reply.started":"2023-05-24T19:11:06.040261Z","shell.execute_reply":"2023-05-24T19:11:06.045393Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)","metadata":{"id":"IDn2rPQ8Wzog","outputId":"1c22d534-ec03-476d-def9-aff9df4e0561","execution":{"iopub.status.busy":"2023-05-24T19:11:09.108409Z","iopub.execute_input":"2023-05-24T19:11:09.108755Z","iopub.status.idle":"2023-05-24T19:11:09.143280Z","shell.execute_reply.started":"2023-05-24T19:11:09.108726Z","shell.execute_reply":"2023-05-24T19:11:09.142204Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Using device: cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"class MyDataset_Binary(torch.utils.data.Dataset):\n  'Characterizes a dataset for PyTorch'\n  def __init__(self, x, labels,transform):\n        'Initialization'\n        super(MyDataset_Binary, self).__init__()\n        self.labels = labels\n        self.x = x\n        self.transform = transform\n\n  def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.x)\n\n  def __getitem__(self, index):\n        'Generates one sample of data'\n        if self.transform is None:\n          x =  self.x[index]\n          y = self.labels[index]\n        else:\n          x = self.transform(self.x[index])\n          y = self.labels[index]\n       \n        return x, y\n       \n","metadata":{"id":"53u2EuSqZW92","execution":{"iopub.status.busy":"2023-05-24T19:11:11.364691Z","iopub.execute_input":"2023-05-24T19:11:11.365051Z","iopub.status.idle":"2023-05-24T19:11:11.372382Z","shell.execute_reply.started":"2023-05-24T19:11:11.365021Z","shell.execute_reply":"2023-05-24T19:11:11.371436Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def show_samples(x):\n  x = x.permute(0, 2, 3, 1).detach().cpu().numpy()\n  img = image_grid(x)\n  plt.figure(figsize=(8,8))\n  plt.axis('off')\n  plt.imshow(img)\n  plt.show()\ndef image_grid(x):\n  size =image_size# config.data.image_size train_model\n  channels =3# config.data.num_channels\n  img = x.reshape(-1, size, size, channels)\n  w = int(np.sqrt(img.shape[0]))\n  img = img.reshape((w, w, size, size, channels)).transpose((0, 2, 1, 3, 4)).reshape((w * size, w * size, channels))\n  return img","metadata":{"id":"0YH-zDcYWnKA","execution":{"iopub.status.busy":"2023-05-24T19:11:13.867736Z","iopub.execute_input":"2023-05-24T19:11:13.868078Z","iopub.status.idle":"2023-05-24T19:11:13.875698Z","shell.execute_reply.started":"2023-05-24T19:11:13.868050Z","shell.execute_reply":"2023-05-24T19:11:13.874783Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"orig_transform = transforms.Compose([\n            transforms.Resize([image_size,image_size]),\n            transforms.ToTensor()\n        ])\n\ntrans_to_32 = transforms.Compose([  transforms.Resize((image_size,image_size))])\n\nimg_transform_32 = transforms.Compose([transforms.ToTensor(), transforms.Resize((image_size,image_size))])","metadata":{"id":"Uyuzx4BDZQUO","execution":{"iopub.status.busy":"2023-05-24T19:11:50.407826Z","iopub.execute_input":"2023-05-24T19:11:50.408198Z","iopub.status.idle":"2023-05-24T19:11:50.414061Z","shell.execute_reply.started":"2023-05-24T19:11:50.408164Z","shell.execute_reply":"2023-05-24T19:11:50.412882Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_dataset(class_1):\n  \n  orig_transform = transforms.Compose([\n            transforms.Resize([image_size,image_size]),\n            transforms.ToTensor()\n        ])\n\n  trans_to_32 = transforms.Compose([  transforms.Resize((image_size,image_size))])\n\n  img_transform_32_1 = transforms.Compose([transforms.Grayscale(3), transforms.ToTensor(), transforms.Resize((image_size,image_size))])\n\n  img_transform_32_2 = transforms.Compose([transforms.Grayscale(3), transforms.ToTensor(), transforms.Resize((image_size,image_size))])\n\n  train_1 = MNIST(f'./data/MNIST/train', train=True, download=True, transform=img_transform_32_1)\n  images_train=[]\n  for x,y in train_1:\n      if y==class_1:\n        images_train.append(x)\n  train_tensor=torch.stack(images_train)\n   \n  testset = MNIST(f'./data/MNIST/test', train=False, download=True, transform=img_transform_32_1)\n\n  test_labels=[]\n  images_test=[]\n  for x,y in testset:\n    images_test.append(x)\n    if y==class_1:\n        test_labels.append(0)\n    else:test_labels.append(1)\n  images_test_tensor=torch.stack(images_test)\n\n  mir_data_set_test = MyDataset_Binary(images_test_tensor, test_labels, trans_to_32)\n  Test_loader_mir = DataLoader(mir_data_set_test, batch_size=10, shuffle=False)\n\n  normal_train_count = train_tensor.shape[0] \n\n  exposure_data = torch.from_numpy(np.load(exposure_addr))\n  exposure_data = (exposure_data + 1) / 2\n   \n  while len(train_tensor) > len(exposure_data):\n    exposure_data = exposure_data.repeat(2, 1, 1, 1)\n  \n  exposure_data = exposure_data[:len(train_tensor)]\n  \n  fake_label=[1]*exposure_data.shape[0]\n  fake_dataset = MyDataset_Binary(exposure_data,fake_label, trans_to_32)\n  normal_label=[0]*train_tensor.shape[0]\n\n  train_dataset = MyDataset_Binary(train_tensor, normal_label, trans_to_32)\n\n  train_dev_sets = torch.utils.data.ConcatDataset([train_dataset, fake_dataset])\n  bin_train_loader = torch.utils.data.DataLoader(train_dev_sets, shuffle=True, batch_size=10)\n  \n  print(train_tensor.shape, exposure_data.shape)\n\n  return bin_train_loader, Test_loader_mir","metadata":{"id":"LZgQeRUqGv-C","execution":{"iopub.status.busy":"2023-05-24T19:11:54.067078Z","iopub.execute_input":"2023-05-24T19:11:54.067923Z","iopub.status.idle":"2023-05-24T19:11:54.081987Z","shell.execute_reply.started":"2023-05-24T19:11:54.067886Z","shell.execute_reply":"2023-05-24T19:11:54.080968Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"_mean = (0.485, 0.456, 0.406)\n_std = (0.229, 0.224, 0.225)\n\nmu = torch.tensor(_mean).view(3,1,1).cuda()\nstd = torch.tensor(_std).view(3,1,1).cuda()\n\nclass PreActBlock(nn.Module):\n    '''Pre-activation version of the BasicBlock.'''\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride:int=1):\n        super(PreActBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out += shortcut\n        return out\n\n\nclass PreActBottleneck(nn.Module):\n    '''Pre-activation version of the original Bottleneck module.'''\n    expansion = 4\n\n    def __init__(self, in_planes, planes, stride:int=1):\n        super(PreActBottleneck, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(x))\n        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n        out = self.conv1(out)\n        out = self.conv2(F.relu(self.bn2(out)))\n        out = self.conv3(F.relu(self.bn3(out)))\n        out += shortcut\n        return out\n\n\nclass PreActResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes:int=2):\n        super(PreActResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.bn = nn.BatchNorm2d(512 * block.expansion)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.relu(self.bn(out))\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return out\n\n\ndef PreActResNet18():\n    return PreActResNet(PreActBlock, [2,2,2,2], num_classes=2)\n\ndef PreActResNet34():\n    return PreActResNet(PreActBlock, [3,4,6,3])\n\ndef PreActResNet50():\n    return PreActResNet(PreActBottleneck, [3,4,6,3])\n\ndef PreActResNet101():\n    return PreActResNet(PreActBottleneck, [3,4,23,3])\n\ndef PreActResNet152():\n    return PreActResNet(PreActBottleneck, [3,8,36,3])\n","metadata":{"id":"wjOtXIVrWPQ9","execution":{"iopub.status.busy":"2023-05-24T19:12:00.106845Z","iopub.execute_input":"2023-05-24T19:12:00.107249Z","iopub.status.idle":"2023-05-24T19:12:03.254064Z","shell.execute_reply.started":"2023-05-24T19:12:00.107214Z","shell.execute_reply":"2023-05-24T19:12:03.252881Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n        super(BasicBlock, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                               padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_planes)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        self.droprate = dropRate\n        self.equalInOut = (in_planes == out_planes)\n        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n                               padding=0, bias=False) or None\n    def forward(self, x):\n        if not self.equalInOut:\n            x = self.relu1(self.bn1(x))\n        else:\n            out = self.relu1(self.bn1(x))\n        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n        if self.droprate > 0:\n            out = F.dropout(out, p=self.droprate, training=self.training)\n        out = self.conv2(out)\n        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n\nclass NetworkBlock(nn.Module):\n    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n        super(NetworkBlock, self).__init__()\n        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n        layers = []\n        for i in range(int(nb_layers)):\n            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n        return nn.Sequential(*layers)\n    def forward(self, x):\n        return self.layer(x)\n\nclass WideResNet(nn.Module):\n    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n        super(WideResNet, self).__init__()\n        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n        assert((depth - 4) % 6 == 0)\n        n = (depth - 4) / 6\n        block = BasicBlock\n        # 1st conv before any network block\n        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n                               padding=1, bias=False)\n        # 1st block\n        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n        # 2nd block\n        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n        # 3rd block\n        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n        # global average pooling and classifier\n        self.bn1 = nn.BatchNorm2d(nChannels[3])\n        self.relu = nn.ReLU(inplace=True)\n        self.fc = nn.Linear(nChannels[3], num_classes)\n        self.nChannels = nChannels[3]\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.bias.data.zero_()\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.block1(out)\n        out = self.block2(out)\n        out = self.block3(out)\n        out = self.relu(self.bn1(out))\n        out = F.avg_pool2d(out, 8)\n        out = out.view(-1, self.nChannels)\n        return self.fc(out)","metadata":{"id":"pIJqogBhEzJ6","execution":{"iopub.status.busy":"2023-05-24T19:12:03.583811Z","iopub.execute_input":"2023-05-24T19:12:03.584208Z","iopub.status.idle":"2023-05-24T19:12:03.609375Z","shell.execute_reply.started":"2023-05-24T19:12:03.584172Z","shell.execute_reply":"2023-05-24T19:12:03.608498Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"def auc_softmax_adversarial(model, test_loader, test_attack):\n  soft = torch.nn.Softmax(dim=1)\n  anomaly_scores = []\n  test_labels = []\n  print('AUC Adversarial Softmax Started ...')\n  with tqdm(test_loader, unit=\"batch\") as tepoch:\n \n    torch.cuda.empty_cache()\n    for i, (data, target) in enumerate(tepoch):\n      model.eval()\n      data, target = data.to(device), target.to(device)\n      labels = target.to(device)\n      data = torch.clamp(data, 0, 1)\n      adv_data = test_attack(data, target)\n      output = model(adv_data)\n      probs = soft(output)\n      anomaly_scores += probs[:, 1].detach().cpu().numpy().tolist()\n      test_labels += target.detach().cpu().numpy().tolist()\n\n  auc = roc_auc_score(test_labels, anomaly_scores)\n  print(f'AUC Adversairal - Softmax - score on epoch {epoch} is: {auc * 100}')\n  return auc\n\nfrom sklearn.metrics import roc_auc_score\ndef auc_softmax(model, test_loader   ):\n  soft = torch.nn.Softmax(dim=1)\n  anomaly_scores = []\n  test_labels = []\n  print('AUC Softmax Started ...')\n  with torch.no_grad():\n    with tqdm(test_loader, unit=\"batch\") as tepoch:\n\n      torch.cuda.empty_cache()\n      for i, (data, target) in enumerate(tepoch):\n        model.eval()\n        data, target = data.to(device), target.to(device)\n        data = torch.clamp(data, 0, 1)\n        output = model(data)\n        probs = soft(output)\n        anomaly_scores += probs[:, 1].detach().cpu().numpy().tolist()\n        test_labels += target.detach().cpu().numpy().tolist()\n\n  auc = roc_auc_score(test_labels, anomaly_scores)\n  print(f'AUC - Softmax - score on epoch {epoch} is: {auc * 100}')\n  \n  return auc\n","metadata":{"id":"ElbW05tvZmlQ","execution":{"iopub.status.busy":"2023-05-24T19:11:57.105962Z","iopub.execute_input":"2023-05-24T19:11:57.106320Z","iopub.status.idle":"2023-05-24T19:11:57.119374Z","shell.execute_reply.started":"2023-05-24T19:11:57.106290Z","shell.execute_reply":"2023-05-24T19:11:57.118336Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"epochs = 4","metadata":{"execution":{"iopub.status.busy":"2023-05-24T19:24:56.225884Z","iopub.execute_input":"2023-05-24T19:24:56.226310Z","iopub.status.idle":"2023-05-24T19:24:56.231890Z","shell.execute_reply.started":"2023-05-24T19:24:56.226275Z","shell.execute_reply":"2023-05-24T19:24:56.230944Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"for normal_class in range(0, 1):\n    clean_auc = []\n    adv_auc = []\n    best_adv_auc = None\n\n    bin_train_loader, Test_loader_mir = get_dataset(normal_class) \n\n    for p in range(len(train_attack_epses)):\n        train_attack_eps = train_attack_epses[p]\n        train_attack_steps = 10\n        train_attack_alpha = 2.5 * train_attack_eps / train_attack_steps\n\n        if image_size == 224: model = PretrainedModel(backbone).cuda()\n        else: model = WideResNet(34, 2, 5, dropRate=0.0).cuda()\n        \n        train_attack = PGD(model, eps=train_attack_eps, alpha=train_attack_alpha, steps=train_attack_steps)\n        optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00005)\n\n        for epoch in range(epochs):\n            total_loss, total_num = 0.0, 0\n            loss = nn.CrossEntropyLoss()\n            train_bar = tqdm(bin_train_loader, desc='Train Binary Classifier ...')\n            for (img1, Y) in train_bar:\n                model.train()\n\n                data = torch.clamp(img1, 0, 1)\n                adv_data = train_attack(data.cuda(), Y.cuda())\n\n                optimizer.zero_grad()\n\n                out_1 = model(adv_data.cuda()) \n                loss_ = loss(out_1,Y.cuda())  \n\n                loss_.backward()\n                optimizer.step()\n\n                total_num += adv_data.size(0)\n                total_loss += loss_.item() * adv_data.size(0)\n                total_num += bin_train_loader.batch_size\n                total_loss += loss_.item() * bin_train_loader.batch_size\n\n                train_bar.set_description('Train Robust Epoch :  {} , Clf_B Robust Loss: {:.4f}'.format(epoch ,  total_loss / total_num))\n        \n        test_attack_steps = 100\n        test_attack_alpha = 2.5 * (8/255) / test_attack_steps\n        test_attack = PGD(model, eps=8/255, alpha=test_attack_alpha, steps=test_attack_steps)\n        auc_softmax(model, Test_loader_mir)\n        auc_softmax_adversarial(model, Test_loader_mir, test_attack)","metadata":{"id":"znlsgAPWWPQ_","outputId":"c3c023fd-de87-4a2e-8f84-9b1df265cd54","execution":{"iopub.status.busy":"2023-05-24T19:25:21.409017Z","iopub.execute_input":"2023-05-24T19:25:21.409696Z","iopub.status.idle":"2023-05-24T19:33:32.668112Z","shell.execute_reply.started":"2023-05-24T19:25:21.409661Z","shell.execute_reply":"2023-05-24T19:33:32.667122Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"torch.Size([5923, 3, 32, 32]) torch.Size([5923, 3, 32, 32])\n","output_type":"stream"},{"name":"stderr","text":"Train Robust Epoch :  0 , Clf_B Robust Loss: 0.1672: 100%|██████████| 1185/1185 [01:38<00:00, 12.00it/s]\nTrain Robust Epoch :  1 , Clf_B Robust Loss: 0.0845: 100%|██████████| 1185/1185 [01:38<00:00, 12.02it/s]\nTrain Robust Epoch :  2 , Clf_B Robust Loss: 0.0620: 100%|██████████| 1185/1185 [01:38<00:00, 12.00it/s]\nTrain Robust Epoch :  3 , Clf_B Robust Loss: 0.0444: 100%|██████████| 1185/1185 [01:39<00:00, 11.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"AUC Softmax Started ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [00:04<00:00, 225.07batch/s]\n","output_type":"stream"},{"name":"stdout","text":"AUC - Softmax - score on epoch 3 is: 99.68031358885018\nAUC Adversarial Softmax Started ...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/1000 [00:00<?, ?batch/s]/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n100%|██████████| 1000/1000 [01:09<00:00, 14.29batch/s]","output_type":"stream"},{"name":"stdout","text":"AUC Adversairal - Softmax - score on epoch 3 is: 97.91517715733742\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}